{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KIIDFound(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_kiids(pdf_links, pdf_links_titles, wzor1, wzor2):\n",
    "    wynik=[]\n",
    "    for i in range(len(pdf_links)):\n",
    "        if pdf_links_titles[i] is not None:\n",
    "            link_title = pdf_links_titles[i]\n",
    "        else:\n",
    "            link_title = \"\"\n",
    "        ratio1 = fuzz.partial_ratio(pdf_links[i].lower(), wzor1)\n",
    "        ratio2 = fuzz.partial_ratio(pdf_links[i].lower(), wzor2)\n",
    "        ratio3 = fuzz.partial_ratio(link_title.lower(), wzor1)\n",
    "        ratio4 = fuzz.partial_ratio(link_title.lower(), wzor2)\n",
    "\n",
    "        if ratio1 > 80 or ratio3 > 80 or ratio2 > 95 or ratio4 > 95:\n",
    "\n",
    "            wynik.append(pdf_links[i])\n",
    "    return wynik\n",
    "wzor1 = 'kluczowe informacje dla inwestorow'\n",
    "wzor2 = 'kiid'\n",
    "wzor3 = 'kluczowe-informacje-dla-inwestorow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pdf(url):\n",
    "    r = requests.get(url, stream=True)\n",
    "    domain = url.split(\".\")[1]\n",
    "    if not os.path.exists(domain):\n",
    "        os.makedirs(domain, exist_ok=True) \n",
    "    nazwa = domain +'/' + url.split(\"/\")[-1]\n",
    "    with open(nazwa, 'wb') as f:\n",
    "        f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrap_all_kiids(url, visited: list):\n",
    "    def scrape_kiid(url, visited: list):\n",
    "        if len(visited)>0 and url in visited:\n",
    "            return\n",
    "        visited.append(url)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "        except:\n",
    "            return\n",
    "        print(url)\n",
    "        try:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        except:\n",
    "            return\n",
    "        hrefs = soup.findAll('a', href=True)\n",
    "        titles = [hrefs.string for hrefs in hrefs]\n",
    "        res = {}\n",
    "        for key in hrefs:\n",
    "            for value in titles:\n",
    "                res[key[\"href\"]] = value\n",
    "                titles.remove(value)\n",
    "                break\n",
    "        \n",
    "        array = np.unique([a[\"href\"] for a in hrefs])\n",
    "        if len(array) == 0:\n",
    "            return\n",
    "        no_https = array[~np.char.startswith(array, \"http\")]\n",
    "        pdf_links = no_https[np.char.endswith(no_https, \"pdf\")].tolist()\n",
    "        pdf_links_titles = list(map(res.get, pdf_links))\n",
    "        no_https = no_https[~np.char.endswith(no_https, \"pdf\")]\n",
    "        inner_site_links = no_https[np.char.startswith(no_https, \"/\")] #tu zmiana, żeby działało niezależnie od domeny\n",
    "        #inner_site_links = no_https[np.char.endswith(no_https, \"/\")].tolist()\n",
    "        inner_site_links = inner_site_links[~np.char.endswith(inner_site_links, \"zip\")].tolist()\n",
    "        wynik = find_kiids(pdf_links, pdf_links_titles, wzor1 = 'kluczowe informacje dla inwestorow', wzor2 = 'kiid')\n",
    "        if len(wynik) > 1:\n",
    "            wynik_final.extend([domain[:-1]+wynik for wynik in wynik])\n",
    "            raise KIIDFound\n",
    "        #pdf_final_links = pdf_final_links + pdf_links\n",
    "        #pdf_final_links.extend(pdf_links)\n",
    "        visited.append(url)\n",
    "        for link in inner_site_links:\n",
    "            scrape_kiid(domain[:-1]+link, visited)\n",
    "    try:\n",
    "        scrape_kiid(url, visited)\n",
    "    except KIIDFound:\n",
    "        for pdf in wynik_final:\n",
    "            save_pdf(pdf)\n",
    "        print(\"Udalo sie!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = '''1 AgioFunds TFI S.A. www.agiofunds.pl\n",
    "2 Alior TFI S.A. www.aliortfi.com\n",
    "3 Amundi Polska TFI S.A. www.amundi.pl\n",
    "4 Baltic Capital TFI S.A. www.baltictfi.pl\n",
    "5 BNP Paribas TFI S.A. www.tfi.bnpparibas.pl\n",
    "6 BPS TFI S.A. www.bpstfi.pl\n",
    "7 Caspar TFI S.A. www.caspartfi.pl\n",
    "8 EQUES INVESTMENT TFI S.A. www.eitfi.pl\n",
    "9 Esaliens TFI S.A. www.esaliens.pl\n",
    "10 Generali Investments TFI S.A. www.generali-investments.pl\n",
    "11 Investors TFI S.A. www.investors.pl\n",
    "12 Ipopema TFI S.A. www.ipopema.pl\n",
    "13 MILLENNIUM TFI S.A. www.millenniumtfi.pl\n",
    "14 Nationale-Nederlanden TFI S.A. www.metlife.pl\n",
    "15 NN Investment Partners TFI S.A. www.nntfi.pl\n",
    "16 Noble Funds TFI S.A. www.noblefunds.pl\n",
    "17 OPERA TFI S.A. www.opera-tfi.pl\n",
    "18 Pekao TFI S.A. www.pekaotfi.pl\n",
    "19 PFR TFI S.A. www.pfrtfi.pl\n",
    "20 PKO TFI S.A. www.pkotfi.pl\n",
    "21 Quercus TFI S.A. www.qtfi.pl\n",
    "22 Rockbridge TFI S.A. www.rockbridge.pl\n",
    "23 Santander TFI S.A. www.santandertfi.pl\n",
    "24 SKARBIEC TFI S.A. www.skarbiec.pl\n",
    "25 Superfund TFI S.A. www.superfund.pl\n",
    "26 Templeton Asset Management (Poland) TFI S.A. www.franklintempleton.pl\n",
    "27 TFI AGRO S.A. www.tfiagro.pl\n",
    "28 TFI Allianz Polska S.A. www.allianz.pl\n",
    "29 TFI Energia S.A. www.tfienergia.pl\n",
    "4\n",
    "30 TFI PZU SA www.pzu.pl\n",
    "31 Uniqa TFI S.A. www.uniqa.pl\n",
    "32 VIG/C-QUADRAT TFI S.A. www.vigcq-tfi.p'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = n.split()\n",
    "nazwy = np.array(n)\n",
    "domains = nazwy[np.char.startswith(nazwy,'www')]\n",
    "domains = [\"https://\" + i +'/' for i in domains]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['https://www.amundi.pl/',\n",
    " 'https://www.baltictfi.pl/',\n",
    " 'https://www.tfi.bnpparibas.pl/',\n",
    " 'https://www.bpstfi.pl/',\n",
    " 'https://www.caspar.com.pl/',\n",
    " 'https://www.eitfi.pl/',\n",
    " 'https://www.esaliens.pl/',\n",
    " 'https://www.generali-investments.pl/',\n",
    " 'https://www.investors.pl/',\n",
    " 'https://www.ipopema.pl/',\n",
    " 'https://www.millenniumtfi.pl/',\n",
    " 'https://www.nn.pl/',\n",
    " 'https://www.nntfi.pl/',\n",
    " 'https://www.noblefunds.pl/',\n",
    " 'http://www.opera.pl/',\n",
    " 'https://www.pekaotfi.pl/',\n",
    " 'https://www.pfrtfi.pl/',\n",
    " 'https://www.pkotfi.pl/',\n",
    " 'https://www.qtfi.pl/',\n",
    " 'https://www.rockbridge.pl/',\n",
    " 'https://www.santander.pl/tfi/',\n",
    " 'https://www.skarbiec.pl/',\n",
    " 'https://www.superfund.pl/',\n",
    " 'https://www.franklintempleton.pl/',\n",
    " 'https://www.tfiagro.pl/',\n",
    " 'https://www.allianz.pl/',\n",
    " 'https://www.tfienergia.pl/',\n",
    " 'https://www.pzu.pl/',\n",
    " 'https://www.uniqa.pl/',\n",
    " 'https://www.vigcq-tfi.p/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.amundi.pl/'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = domains[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapp_pages(domains):\n",
    "    for domain in domains:\n",
    "        visited = []\n",
    "        wynik_final = []\n",
    "        start = datetime.now()\n",
    "        scrap_all_kiids(domain, visited)\n",
    "        end = datetime.now()\n",
    "        #print(domain + \": \" + str(end-start))\n",
    "        #print(wynik_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.dummy import Pool\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_scrapp(domains, scrapp_pages):\n",
    "    pool = Pool(cpu_count())\n",
    "    results = pool.map(scrapp_pages, domains)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_scrapp(domains, scrapp_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
